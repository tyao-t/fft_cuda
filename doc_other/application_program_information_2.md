# Reference Letter Details

I simply wish to share a few details that may be helpful when preparing the recommendation:

1. I completed all three projects individually, whereas many of my peers worked in groups. Although it was challenging, this experience allowed me to deepen my understanding of the material and helped me grow both technically and personally.

2. For the CUDA FFT project, I did not reference anyone else's CUDA FFT implementation or any open-source official implementation. While my solution was imperfect, it was a complex task that I learned a great deal from. One note (in addition to the README) is that when writing the core functions, I used CuBLAS and CuComplex and paid attention to memory coalescing, thread coarsening, and minimizing control divergence, and there was a gap in the `.ipynb` file that could have mistakenly marked the end of the demonstration. 

3. For Project 1, I spent significant time on feature engineering and applied creative thinking through the use of MPI (Message Passing Interface), which resulted in a low RMSE (Root Mean Square Error). While I am not certain if anyone achieved a lower score, I am proud of the effort and learning that went into this project. I invested considerable thought into using MPI for feature engineering and other nuanced coding challenges, rather than relying on scikit-learn library functions, which you can certainly re-review.

4. In the 2nd project, I focused on implementing practical and applicable features such as reconstructing missing values and handling categorical features using vector assemblers. This included uploading partitioned data into Databricks' distributed file system and platform. Although I was affected by illness at the time, I did my best to complete the project and apologize for any potential shortcomings this may have caused. I successfully incorporated two categorical features into both Gradient Boosted Trees and Linear Regression, produced the RMSE prediction through parameter searching, and briefly discussed the general advantages of decision trees and Sparkâ€™s MLLib implementation.

5. The program I am applying to, **Master of Computing - Artificial Intelligence Specialisation**, is not a PhD program. The program offers flexibility, allowing students to choose between completing full coursework or undertaking an optional research thesis component. The research thesis is not compulsory, and I may or may not choose the research option, depending on the opportunities that arise. I believe my previous coursework and projects have prepared me well for either pathway.

Lastly, I would greatly appreciate it if you could compare my abilities to those of students in the **Master of Science in Data Science and Machine Learning** program (the vast majority of students in DSA5208 are from this program, and it is the 1st or 2nd most competitive Master's program at NUS). In particular, I would be grateful if you could speak to my Python programming skills, my proficiency with libraries (such as Spark MLLib, scikit-learn, and mpi4py), my ability to work with C++ and CUDA for GPU, and my overall (distributed and parallel) machine learning/AI ability and potential. Your insights into how my skills and potential compare to **other top-performing MSc. DSML students** would be highly valuable.

If you find yourself pressed for time, I completely understand. In that case, please feel free to prioritize writing succinct but impactful comments in the recommendation form. I believe the evaluators will pay close attention to the selection of checkboxes, so focusing on those can have a significant effect.

**Note:** You can save a copy of the letter in case another submission to a different program is necessary in the future.

Thank you very much for your time and support. I truly appreciate your support.
