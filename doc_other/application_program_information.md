## 1. Program Overview, Goals, and Future Aspirations

The program is the [Master of Computing - Artificial Intelligence Specialization](https://www.comp.nus.edu.sg/programmes/pg/mai/). This isn't a PhD application but rather a self-funded endeavor. I've been aware that the NUS President and Singapore's Minister of Education have been actively encouraging lifelong learning and participation in Master's programs. They have introduced [a 20% tuition reduction for NUS alumni, regardless of nationality, or a 40% tuition fee reduction for Singapore citizens and PRs](https://news.nus.edu.sg/adult-learning-made-more-affordable-nus-offers-40-rebate-on-fees-for-over-80-masters-degree-programmes). My primary goal is to deepen my knowledge in AI/ML, in an attempt to achieve and maintain a competitive edge in this rapidly evolving field. There will be an opportunity to attend 6-10 classes and optionally to write a Master's level thesis. If the opportunity arises, I will see if I can engage in more advanced research with some PhD students or professors, such as contributing to conferences. I will simply try to deliver my best effort in these endeavors and to contribute to NUS’ academics, upholding the reputation of NUS alumni and students of Chinese descent.

## 2. Final Remarks on 3 Projects

### Project 3: CUDA FFT

The CUDA FFT project is one that I dedicated significant effort to. The GPU at the time didn’t have an assignment project, and FFT is a classic algorithm in competitive programming, but it was my first time implementing it on a GPU. I would greatly appreciate it if you could carefully review the quality of my C++ code. I believe it compares favorably with most of my peers. One note (in addition to the README) is that when writing the core functions, I paid special attention to minimizing control divergence, and there was a gap in the `.ipynb` file that could have mistakenly marked the end of the demonstration.

![CUDA FFT Project](https://cdn.discordapp.com/attachments/809201638275153982/1278537720372658186/img_v3_02e7_1ff50a65-53c4-481e-9c2c-bae19ed58ehu.jpg?ex=66d12a8a&is=66cfd90a&hm=a58038216d152870e132035c3078960b4d4936ae5c78bd8148975b503d44c2b0&)

### Project 2: Spark Air ML

The first two projects were written in Python. On the final day, I successfully incorporated two categorical features into both Gradient Boosted Trees and Linear Regression, produced the RMSE prediction through parameter searching, and briefly discussed the general advantages of decision trees and Spark's MLLib implementation. I apologize for any delays in that project; unfortunately, the inflammation cost me two full days.

![Python and Decision Trees Project](https://cdn.discordapp.com/attachments/809201638275153982/1278537720674652170/img_v3_02e7_9198da9e-e853-4a7d-bcbe-c2fd66c807hu.jpg?ex=66d12a8a&is=66cfd90a&hm=4672617de89dc0ed16dd9f1144f83ec525f5c60c6f57c08fe0705e5215a104d7&)

### Project 1: MPI Kernel Regression

The first project, involving MPI, was likely the most demanding. I invested a lot of thought into using MPI for feature engineering and other nuanced coding challenges, rather than relying on scikit-learn library functions. If you ever have the chance re-review the code, you'll find that it contains a great deal of subtle implementation details. Thank you!
